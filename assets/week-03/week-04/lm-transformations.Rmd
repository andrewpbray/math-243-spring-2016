---
title: "Extending the Linear Model II"
output:
  ioslides_presentation:
    incremental: true
---

## Example: Truck prices

Can we use the age of a truck to predict what it's price should be?  Consider a 
random sample of 43 pickup trucks.

```{r echo = FALSE}
pickups <- read.csv("http://andrewpbray.github.io/data/pickup.csv")
plot(price ~ year, data = pickups, col = "steelblue", pch = 16)
```


## Example: Truck prices

Can we use the age of a truck to predict what it's price should be?  Consider a 
random sample of 43 pickup trucks *from the last 20 years*.

```{r echo = FALSE}
plot(price ~ year, data = subset(pickups, year >= 1994), col = "steelblue", pch = 16)
m1 <- lm(price ~ year, data = subset(pickups, year >= 1994))
```


## Linear nodel?

```{r, echo=FALSE}
summary(m1)$coef
plot(price ~ year, data = subset(pickups, year >= 1994), col = "steelblue", pch = 16)
abline(m1, lwd = 2)
```


## Linearity and normality {.build}

```{r, echo=FALSE}
par(mfrow = c(1, 2))
plot(m1, 1:2)
```

The normality assumption on the errors seems fine but there seems to be a quadratic
trend in the mean function.


## Constant variance and influence {.build}

```{r echo = FALSE}
par(mfrow = c(1, 2))
plot(m1, c(3, 5))
```

One observation (44) should be investigated for its influence.  There is
evidence of increasing variance in the residuals.

## Transformations

![tranformations](http://i1.wp.com/littlebylisten.com/wp-content/uploads/2013/08/breaking-bad.jpg)

Say you fit a linear model to data and find the residual plots look awful. One
strategy to regain a valid model is to transform your data.


## {.build}

```{r, echo=1, fig.height=3}
pickups2 <- transform(pickups, log_price = log(price))
par(mfrow = c(1, 2))
hist(pickups$price, main = "")
hist(pickups2$log_price, main = "")
```

Variables that span multiple orders of magnitude often benefit from a natural
log transformation.

\[ Y_t = log_e(Y) \]


## Log-transformed linear model

```{r, echo=FALSE}
m2 <- lm(log_price ~ year, data = subset(pickups2, year >= 1994))
summary(m2)$coef
plot(log_price ~ year, data = subset(pickups2, year >= 1994), col = "steelblue", pch = 16)
abline(m2, lwd = 2)
```


## Linearity and normality {.build}

```{r, echo=FALSE}
par(mfrow = c(1, 2))
plot(m2, 1:2)
```

The residuals from this model appear less normal, though the quadratic trend in
the mean function is now less apparent.


## Constant variance and influence {.build}

```{r echo = FALSE}
par(mfrow = c(1, 2))
plot(m2, c(3, 5))
```

There are no points flagged as influential and our variance has been stabilized.


## Transformations summary {.build}

- If a linear model fit to the raw data leads to questionable residual plots,
consider transformations.
- Count data and prices often benefit from transformations.
- The natural log and the square root are the most common, but you can use any 
transformation you like.
- Transformations may change model interpretations.
- Non-constant variance is a serious problem but it can often be solved by transforming
the response.
- Transformations can also fix non-linearity, as can polynomials.


