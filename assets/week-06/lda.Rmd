---
title: "Linear Discriminant Analysis"
output: ioslides_presentation
---

```{r echo = FALSE}
library(knitr)
opts_chunk$set(warning = FALSE, message = FALSE)
```


## R Resources

- DataCamp
- Slack


## Example: Credit Default

```{r}
library(ISLR)
data(Default)
head(Default)
```

$$
\delta_k(x) = x \cdot \frac{\mu_k}{\sigma^2} - \frac{\mu_k^2}{2\sigma^2} + \log (\pi_k)
$$

## Find Estimates

```{r}
library(dplyr)
est <- Default %>%
  group_by(default) %>%
  summarize(n = n(),
            prop = n/nrow(Default),
            mu = mean(balance),
            ssx = var(balance) * (n - 1))
est
```

## Find Estimates {.build}

Pull off estimates (and convert class).

```{r}
pi_n <- as.numeric(est[1, 3])
pi_y <- as.numeric(est[2, 3])
mu_n <- as.numeric(est[1, 4])
mu_y <- as.numeric(est[2, 4])
sig_sq <- (1/(nrow(Default) - 2)) * sum(est$ssx)
```

Write linear discriminant function.

```{r}
my_lda <- function(x, pi, mu, sig_sq) {
  x * (mu/sig_sq) - (mu^2)/(2 * sig_sq) + log(pi)
}
```


## {.build}

```{r}
d_n <- my_lda(Default$balance, pi_n, mu_n, sig_sq)
d_y <- my_lda(Default$balance, pi_y, mu_y, sig_sq)
```

```{r, echo = FALSE, fig.width=5.5, fig.height = 4, fig.align = "center"}
library(ggplot2)
balance <- seq(0, max(Default$balance), length.out = 50)
dx <- c(my_lda(balance, pi_n, mu_n, sig_sq), my_lda(balance, pi_y, mu_y, sig_sq))
default <- as.factor(rep(c("No", "Yes"), each = 50))
df <- data.frame(balance = rep(balance, 2), dx, default)

ggplot(df, aes(x = balance, y = dx, color = default)) +
  geom_line(lwd = 1.3) + 
  theme_bw()
```


## Comparing decision boundaries

```{r, echo = FALSE}
Default <- mutate(Default, defaultYes = ifelse(default == "Yes", 1, 0))
  
p3 <- ggplot(Default, aes(x = balance, y = defaultYes)) +
  geom_point(pch = 1, alpha = .3, color = "steelblue") + 
  ylab("probability of default") + 
  theme_bw()

m1 <- glm(default ~ balance, data = Default, family = binomial)
thresh <- (log(.5/.5) - m1$coef[1])/m1$coef[2]

p3 + geom_vline(xintercept = 2000, col = 2) +
  geom_vline(xintercept = thresh)
```



## Comparing predictions {.build}

```{r}
m1 <- glm(default ~ balance, data = Default, family = binomial)
my_log_pred <- ifelse(m1$fit < 0.5, "No", "Yes")
my_lda_pred <- ifelse(d_n > d_y, "No", "Yes")
```

```{r}
data.frame(log_pred = my_log_pred[8459:8464],
           lda_pred = my_lda_pred[8459:8464],
           true = Default$default[8459:8464])
```


## Confusion Matrix {.build}

```{r}
conf_lda <- table(my_lda_pred, Default$default)
conf_lda
conf_log <- table(my_log_pred, Default$default)
conf_log
```


## Assessing predictions

Training misclassification rate (analog of MSE)

$$
\frac{1}{n}\sum_{i = 1}^n I(y_i \ne \hat{y_i})
$$

LDA:

```{r}
(1/nrow(Default)) * (conf_lda[2, 1] + conf_lda[1, 2])
```

Logisitic:

```{r}
(1/nrow(Default)) * (conf_log[2, 1] + conf_log[1, 2])
```


## Activity

Compare the *testing* misclassification rate of logistic versus LDA. The code 
can be found at `github.com/andrewpbray/math-243/assets/week-06/lda.Rmd`. Please
separate into testing and training as follows:

```{r}
set.seed(39)
test_ind <- sample(1:10000, size = 5000)
Default_test <- Default[test_ind, ]
Default_train <- Default[-test_ind, ]
```


## Fit Models (train)

```{r}
m1 <- glm(default ~ balance, data = Default_train, family = binomial)

est <- Default_train %>%
  group_by(default) %>%
  summarize(n = n(),
            prop = n/nrow(Default_train),
            mu = mean(balance),
            ssx = var(balance) * (n - 1))
```


## Make predictions (test)

```{r}
log_pred <- predict(m1, newdata = Default_test, type = "response")

d_n <- my_lda(Default_test$balance, pi_n, mu_n, sig_sq)
d_y <- my_lda(Default_test$balance, pi_y, mu_y, sig_sq)

my_log_pred <- ifelse(log_pred < 0.5, "No", "Yes")
my_lda_pred <- ifelse(d_n > d_y, "No", "Yes")
```


## Confusion Matrices

```{r}
(conf_log <- table(my_log_pred, Default_test$default))
(conf_lda <- table(my_lda_pred, Default_test$default))
```


## Misclassification Rate

```{r}
(1/nrow(Default_test)) * (conf_log[2, 1] + conf_log[1, 2])
(1/nrow(Default_test)) * (conf_lda[2, 1] + conf_lda[1, 2])
```





